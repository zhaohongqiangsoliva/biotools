# This is an example of how you can use udocker containers with slurm
# *This is not a complete configuration file!* The
# content here should be copy pasted into the backend -> providers section
# of cromwell.example.backends/cromwell.examples.conf in the root of the repository.
# You should uncomment lines that you want to define, and read carefully to customize
# the file. If you have any questions, please open an issue at
# https://www.github.com/broadinstitute/cromwell/issues

# Documentation
# https://cromwell.readthedocs.io/en/develop/tutorials/Containers/#configuration
#include required(classpath("application"))


docker {
    hash-lookup {
        enable = false
            }
}
call-caching {
  enabled = true
  invalidate-bad-cache-results = true
}

backend {
  default = slurm

  providers {
    slurm {
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"                                                                                     
      config {
	concurrent-job-limit = 10
        #filesystems {
         # local {
          #  caching {
              # When copying a cached result, what type of file duplication should occur. Attempted in the order listed below:
     #         duplication-strategy: [
      #          "hard-link", "soft-link", "copy"
       #       ]

              # Possible values: file, path
              # "file" will compute an md5 hash of the file content.
              # "path" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to "soft-link",
              # in order to allow for the original file path to be hashed.
              # Default: file
    #          hashing-strategy: "file"

              # When true, will check if a sibling file with the same name and the .md5 extension exists, and if it does, use the content of this file as a hash.
              # If false or the md5 does not exist, will proceed with the above-defined hashing strategy.
              # Default: false
   #           check-sibling-md5: false
  #          }
 #         }
#        }


        runtime-attributes = """
        Int runtime_minutes = 600
        Int memory_mb = 10000 
	Int cpus = 5
        Int requested_memory_mb_per_core = 10000
        String? docker
        """

        submit = """
            sbatch \
              --wait \
              -J ${job_name} \
              -D ${cwd} \
              -t ${runtime_minutes} \
	            -p wzhcexclu06 \
              ${"-c " + cpus} \
              ${true="--mem=" false="" defined(memory_mb)}${memory_mb}\
              --wrap "/bin/bash ${script}"
        """

        submit-docker = """
          # Pull the image using the head node, in case our workers don't have network access
        #  udocker pull ${docker}

          sbatch \
            -J ${job_name} \
            -D ${cwd} \
            -t ${runtime_minutes} \
	    -p wzhcexclu06 \
            ${"-c " + cpus} \
	   ${true="--mem=" false="" defined(memory_mb)}${memory_mb}\
           --wrap "udocker run -v ${cwd}:${docker_cwd} ${docker} ${job_shell} ${docker_script}"
        """

        kill = "scancel ${job_id}"
        check-alive = "squeue -j ${job_id}"
        job-id-regex = "Submitted batch job (\\d+).*"
      }
    }
  }
}


